{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d59651-ef7c-4114-8334-bcbe149f5651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import faiss\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import json\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "openai.api_key = \"sk-XXXXXXX\"\n",
    "openai_api_key = openai.api_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
    "\n",
    "my_embedding_model = OpenAIEmbeddings(model=\"gpt-3.5-turbo\")\n",
    "my_llm_model = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "def split_documents(documents):\n",
    "    doc_chunks = []\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=5000,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "        chunk_overlap=400,\n",
    "    )\n",
    "    for doc in documents:\n",
    "        chunks = text_splitter.split_text(doc.page_content)\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            doc = Document(\n",
    "                page_content=chunk, metadata={\"title\": doc.metadata[\"title\"], \"chunk\": i, \"abstract\": doc.metadata[\"abstract\"],  \"year\": doc.metadata[\"year\"], \"contributors\": doc.metadata[\"contributors\"], \"screening1\": doc.metadata[\"screening1\"], \"screening2\": doc.metadata[\"screening2\"], \"refid\": doc.metadata[\"refid\"]}\n",
    "\n",
    "                )\n",
    "            # Add sources a metadata\n",
    "            doc.metadata[\"source\"] = f\"{doc.metadata['page']}-{doc.metadata['chunk']}\"\n",
    "            doc_chunks.append(doc)\n",
    "\n",
    "def write_file(filename, content):\n",
    "    with open(filename, 'wb') as file:\n",
    "        file.write(content)\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def docs_to_index(docs, openai_api_key):\n",
    "    index = FAISS.from_documents(\n",
    "        docs, OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "    )  # Create a searchable index of the chunks\n",
    "\n",
    "    return index\n",
    "\n",
    "def store_index_in_db(index, name):\n",
    "    faiss.write_index(index.index, \"docs.index\")\n",
    "    # Open the file and dump to local storage\n",
    "    write_file(f\"{name}.index\", read_file(\"docs.index\"))\n",
    "    index.index = None\n",
    "    write_file(f\"{name}.pkl\", pickle.dumps(index))\n",
    "\n",
    "\n",
    "def load_index_from_db(index_name):\n",
    "    findex = read_file(f\"{index_name}.index\")\n",
    "    write_file(\"docs.index\", findex)\n",
    "    index = faiss.read_index(\"docs.index\")\n",
    "    VectorDB = pickle.loads(read_file(f\"{index_name}.pkl\"))\n",
    "    VectorDB.index = index\n",
    "    return VectorDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391603ebe8399782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-01T11:43:03.282855Z",
     "start_time": "2023-10-01T11:43:03.131058Z"
    },
    "collapsed": false
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8465f0d-8f6d-4a7b-a9e4-90c351fcb0c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"data/preprocessed_articles.pkl\", \"rb\") as input_file:\n",
    "    reviewdf = pickle.load(input_file)\n",
    "    \n",
    "pattern = r'(enlEndNote\\d+)'\n",
    "reviewdf['uniqueid'] = reviewdf['record'].str.extract(pattern)\n",
    "print(len(reviewdf['uniqueid'].unique()))\n",
    "\n",
    "\n",
    "print(reviewdf['screening1'].value_counts())\n",
    "print(reviewdf['screening2'].value_counts())\n",
    "print(reviewdf.groupby('screening1')['screening2'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabbc27-2bf0-4aa3-8313-29954b4ea6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print the shape of the dataframe 'reviewdf' to see its dimensions (rows x columns)\n",
    "print(reviewdf.shape)\n",
    "\n",
    "# The goal of this loop is to identify a column that has a unique value for every row, \n",
    "# suggesting it could be used as an article ID.\n",
    "\n",
    "# Loop through each column of the dataframe 'reviewdf'\n",
    "for column in reviewdf.columns:\n",
    "    # Check if the number of unique values in the column equals 4662\n",
    "    if len(reviewdf[column].unique()) == 4662:\n",
    "        # If the condition is met, print the column name, \n",
    "        # the number of unique values, and the length of the first element in that column\n",
    "        # This can give insight into the type of unique identifier (e.g., length might hint at a hash vs a numeric ID)\n",
    "        print(f\"{column}\\t{len(reviewdf[column].unique())}:\\t{len(reviewdf[column][0])}\")\n",
    "        \n",
    "        \n",
    "# Find the length of the largest string in 'record' column\n",
    "max_length = reviewdf['record'].str.len().max()\n",
    "\n",
    "print(max_length)\n",
    "# Get the records with the longest string length\n",
    "longest_records = reviewdf[reviewdf['record'].str.len() == max_length]\n",
    "print(longest_records['record'].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6722f8340c207d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Embedding publications data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ff2f25383df86",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pattern = r'(enlEndNote\\d+)'\n",
    "reviewdf['uniqueid'] = reviewdf['record'].str.extract(pattern)\n",
    "\n",
    "# \n",
    "selected_cols = ['uniqueid', 'record', 'database', 'source-app', 'rec-number', 'foreign-keys', 'key',  'ref-type', 'contributors', 'titles', 'title', 'secondary-title', 'short-title', 'pages', 'volume', 'number',\n",
    "       'edition','date','dates', 'year', 'pub-dates', 'date',\n",
    "       'isbn', 'accession-num','urls', 'electronic-resource-num','remote-database-name','authors', 'author', 'related-urls', 'url']\n",
    "article_collection = reviewdf[selected_cols].copy()\n",
    "\n",
    "article_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a13f384d6428e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We divide the database in chunks of 20 articles, so we can analyze them in batches. These batches are embedded individually and saved in pickles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba90998a4fd895",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chaintype = 'stuff'\n",
    "my_llm_model = ChatOpenAI(model_name='gpt-3.5-turbo-0613', temperature=0)\n",
    "\n",
    "for start in tqdm(range(0, len(article_collection), 20)):\n",
    "    end = start + 20\n",
    "    articles_chunk = article_collection[start:end].copy()\n",
    "    \n",
    "    #print(f\"vectordbs/collection_{start}_{end}\")\n",
    "\n",
    "    loader = DataFrameLoader(articles_chunk, page_content_column=\"record\")\n",
    "    documents = loader.load()\n",
    "    documents = text_splitter.split_documents(documents)\n",
    "\n",
    "    vectordb = docs_to_index(documents, openai_api_key)\n",
    "    store_index_in_db(vectordb, f\"vectorsdbs2/collection_{start}_{end}\")\n",
    "    #SAVE ALSO THE DATASET\n",
    "    articles_chunk.to_pickle(f\"vectorsdbs2/df_collection_{start}_{end}.pkl\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71700467c70a5bb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Defining checkpoints schema\n",
    "\n",
    "#### Analyzing chunks original criteria\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206aebb6c8f2f530",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_json(data):\n",
    "    try:\n",
    "        json.loads(data)\n",
    "        return True\n",
    "    except json.JSONDecodeError:\n",
    "        return False\n",
    "\n",
    "def restructure_dict(output, key_renaming):\n",
    "    output = {key_renaming.get(old_key, old_key): value for old_key, value in output.items()}\n",
    "\n",
    "    new_dict = {}\n",
    "    for checkpoint in output.keys():\n",
    "        if 'checkpoint' in checkpoint:\n",
    "            checkpoint_name = checkpoint.split('_')[1]  # Remove the \"checkpoint_\" prefix\n",
    "            new_dict[checkpoint_name] = {\n",
    "                'label': output['checkpoint_'+checkpoint_name],\n",
    "                'reason': output['reason_'+checkpoint_name]\n",
    "            }\n",
    "    return new_dict\n",
    "\n",
    "def check_inclusion_criteria(article_dict):\n",
    "    \"\"\"\n",
    "    Check if an article meets the inclusion criteria.\n",
    "    :param article_dict: dictionary containing analysis of an article.\n",
    "    :return: True if the article should be included, False otherwise.\n",
    "    \"\"\"\n",
    "    response_boolean_vector = [bool(values['label']) for values in output.values()]\n",
    "\n",
    "    # Loop through each checkpoint in the article's dictionary\n",
    "    for checkpoint, values in article_dict.items():\n",
    "        # Check if the 'label' value for this checkpoint is 'False'\n",
    "        if values['label'] == 'False':\n",
    "            # If it is, return False (article should not be included)\n",
    "            return False, response_boolean_vector\n",
    "\n",
    "    # If all of the inclusion criteria were met, return True (article should be included)\n",
    "    return True, response_boolean_vector\n",
    "\n",
    "checkpoints_dict = {\n",
    "    \"Population\": \"f the study population comprises patients with musculoskeletal conditions, with no majority having another primary disease or intellectual disabilities, then return True. Otherwise, return False.\",\n",
    "    \n",
    "    \"Intervention\":  \"If physiotherapists provided one of the intervention/control group treatments alone, then return True. If the treatment of interest was offered by an interdisciplinary team, non-health care professionals, or mostly by a different profession, then return False. If the intervention combines physiotherapy with another treatment and the other treatment is provided in a comparator group, then return True. If the study evaluates the economic aspects of E-interventions, digital interventions or eHealth interventions, then return False\",\n",
    "  \n",
    "    \"Control Group\": \"If there is a control group of any type - for example, wait and see, usual care, placebo, or alternative treatments, then return True. Otherwise, return False.\",\n",
    "    \n",
    "    \"Outcome\": \"If the outcome of the study involves or allows a full economic evaluation, potentially including cost-effectiveness ratios and cost-utility ratios or if the study provides information on the costs and clinical effects of a treatment, then return True. Otherwise, return False.\",\n",
    "    \n",
    "    \"study type\": \"If the article is not a conference abstract, review, study without results (like a protocol), or model-based study, then return True. Otherwise, return False.\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "response_schemas = []\n",
    "\n",
    "for i, (checkpoint, description) in enumerate(checkpoints_dict.items(), 1):\n",
    "    response_schemas.append(\n",
    "        ResponseSchema(\n",
    "            name=f\"checkpoint{i}\",\n",
    "            description=f\"True/False, depending on whether {checkpoint} applies to the text.\"\n",
    "        )\n",
    "    )\n",
    "    response_schemas.append(\n",
    "        ResponseSchema(\n",
    "            name=f\"reason{i}\",\n",
    "            description=f\"The reason for the decision made on {checkpoint}. {description}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# The parser that will look for the LLM output in my schema and return it back to me\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"\"\"Given the following checkpoints with their description from the user, \\\n",
    "                                                   assess whether they apply or not to the text you receive as input below \\\n",
    "                                                   and provide a brief explanation on the why. \\n\n",
    "                                                    {format_instructions}\\n{user_prompt}\"\"\")  \n",
    "    ],\n",
    "    input_variables=[\"user_prompt\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "key_renaming ={}\n",
    "keys_list = list(checkpoints_dict.keys())\n",
    "for i in range(len(keys_list)):\n",
    "    #print(i, keys_list[i])\n",
    "    key_renaming.update({f\"checkpoint{i+1}\": f\"checkpoint_{keys_list[i]}\"})\n",
    "    key_renaming.update({f\"reason{i+1}\": f\"reason_{keys_list[i]}\"})\n",
    "\n",
    "\n",
    "labels_from_user = \"\\n%CHECKPOINTS:\\n\\n\" + '\\n\\n'.join([f\"{key} : {value}\" for key, value in checkpoints_dict.items()])\n",
    "label_query = prompt.format_prompt(user_prompt=labels_from_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3453550fe604c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for start in range(0, len(article_collection), 20):\n",
    "    end = start + 20\n",
    "    filelist.append(f\"{start}_{end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef2f943fea7929",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "record2answer = {}\n",
    "missing_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4684b15f15d4bc87",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chaintype = 'stuff'\n",
    "my_llm_model = ChatOpenAI(model_name='gpt-3.5-turbo-0613', temperature=0)\n",
    "selected_k = 5\n",
    "selected_fetch_k = 20\n",
    "\n",
    "for file in tqdm(filelist):    \n",
    "    db_chunk = pd.read_pickle(f\"vectorsdbs2/df_collection_{file}.pkl\")\n",
    "    rec_numbers = db_chunk['uniqueid'].to_list()\n",
    "    myindex = load_index_from_db(f\"vectorsdbs2/collection_{file}\")\n",
    "    \n",
    "    for recnumber in rec_numbers:\n",
    "        qa_chain = RetrievalQA.from_chain_type(llm=my_llm_model,\n",
    "                                           chain_type=chaintype,\n",
    "                                           retriever=myindex.as_retriever(search_type=\"mmr\",\n",
    "                                                                        search_kwargs={'fetch_k': selected_fetch_k,\n",
    "                                                                                       'k': selected_k,\n",
    "                                                                                       'filter':{'uniqueid': recnumber}}),\n",
    "                                           return_source_documents=True,\n",
    "                                           verbose=False)\n",
    "        try: \n",
    "            if recnumber in record2answer.keys():\n",
    "                pass\n",
    "            else:\n",
    "                llm_response = qa_chain({\"query\": label_query.to_string()})\n",
    "                # print(llm_response)\n",
    "                output = output_parser.parse(llm_response['result'])\n",
    "                output = restructure_dict(output, key_renaming)\n",
    "                # print(\"\\n-----------\\n\")\n",
    "                # print_bullet_points(output)\n",
    "                # print(\"\\n-----------\\n\")\n",
    "                # print(llm_response['source_documents'])\n",
    "                output['sources'] = llm_response['source_documents']\n",
    "                record2answer[recnumber] = output\n",
    "        except:\n",
    "            if recnumber in missing_records:\n",
    "                pass\n",
    "            else:\n",
    "               # print(f\"ERROR in {recnumber}:\\t{llm_response['result']}\")\n",
    "               missing_records.append(recnumber)\n",
    "                \n",
    "\n",
    "    with open('results/record2answer_originalcrits.pkl', 'wb') as file:\n",
    "        pickle.dump(record2answer, file)\n",
    "        \n",
    "    with open('results/missing_records_originalcrits.pkl', 'wb') as file:\n",
    "        pickle.dump(missing_records, file)\n",
    "        \n",
    "print(f\"CORRECTLY analyzed {len(record2answer)}\")\n",
    "print(f\"INCORRECTLY analyzed {len(missing_records)}\")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63163414fbd9f901",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Analyzing chunks original criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5291c963540aa0a9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_json(data):\n",
    "    try:\n",
    "        json.loads(data)\n",
    "        return True\n",
    "    except json.JSONDecodeError:\n",
    "        return False\n",
    "\n",
    "def restructure_dict(output, key_renaming):\n",
    "    output = {key_renaming.get(old_key, old_key): value for old_key, value in output.items()}\n",
    "\n",
    "    new_dict = {}\n",
    "    for checkpoint in output.keys():\n",
    "        if 'checkpoint' in checkpoint:\n",
    "            checkpoint_name = checkpoint.split('_')[1]  # Remove the \"checkpoint_\" prefix\n",
    "            new_dict[checkpoint_name] = {\n",
    "                'label': output['checkpoint_'+checkpoint_name],\n",
    "                'reason': output['reason_'+checkpoint_name]\n",
    "            }\n",
    "    return new_dict\n",
    "\n",
    "def check_inclusion_criteria(article_dict):\n",
    "    \"\"\"\n",
    "    Check if an article meets the inclusion criteria.\n",
    "    :param article_dict: dictionary containing analysis of an article.\n",
    "    :return: True if the article should be included, False otherwise.\n",
    "    \"\"\"\n",
    "    response_boolean_vector = [bool(values['label']) for values in output.values()]\n",
    "\n",
    "    # Loop through each checkpoint in the article's dictionary\n",
    "    for checkpoint, values in article_dict.items():\n",
    "        # Check if the 'label' value for this checkpoint is 'False'\n",
    "        if values['label'] == 'False':\n",
    "            # If it is, return False (article should not be included)\n",
    "            return False, response_boolean_vector\n",
    "\n",
    "    # If all of the inclusion criteria were met, return True (article should be included)\n",
    "    return True, response_boolean_vector\n",
    "\n",
    "checkpoints_dict = {\n",
    "    \"Population\": \"If the study population comprises patients with musculoskeletal conditions, with no majority having another primary disease or intellectual disabilities, then return True. Otherwise, return False.\",\n",
    "    \n",
    "    \"Intervention\": \"If the treatment involves physiotherapy (techniques like exercises, manual therapy, education, and modalities such as heat, cold, ultrasound, and electrical stimulation to aid in patient recovery, pain reduction, mobility enhancement, and injury prevention), or at least one of the intervention/control group treatments was provided exclusively by physiotherapists, then return True. However, if the treatment of interest was offered by an interdisciplinary team, non-health care professionals, or mostly by a different profession to physiotherapists, then return False. \",\n",
    "        \n",
    "    \"Phisiotherapy and another treatment\": \"In case at least one of the intervention/control group treatments was provided exclusively by physiotherapists, if the intervention includes physiotherapy and another treatment and the other treatment is provided in a comparator group, then return True. \",\n",
    "        \n",
    "    \"E-interventions\": \"If the study evaluates the economic aspects of E-interventions, digital interventions or eHealth interventions, then  return False. Otherwise, return True\",\n",
    "    \n",
    "    \"Control Group\": \"If there is a control group of any type - for example, wait and see, usual care, placebo, or alternative treatments, then return True. Otherwise, return False.\",\n",
    "    \n",
    "    \"Outcome\": \"If the outcome of the study involves or allows a full economic evaluation, potentially including cost-effectiveness ratios and cost-utility ratios or if the study provides information on the costs and clinical effects of a treatment  then return True. Otherwise, return False.\",\n",
    "    \n",
    "    \"study type\": \"If the article is not a conference abstract, review, study without results (like a protocol), or model-based study, then return True. Otherwise, return False.\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "response_schemas = []\n",
    "\n",
    "for i, (checkpoint, description) in enumerate(checkpoints_dict.items(), 1):\n",
    "    response_schemas.append(\n",
    "        ResponseSchema(\n",
    "            name=f\"checkpoint{i}\",\n",
    "            description=f\"True/False, depending on whether {checkpoint} applies to the text.\"\n",
    "        )\n",
    "    )\n",
    "    response_schemas.append(\n",
    "        ResponseSchema(\n",
    "            name=f\"reason{i}\",\n",
    "            description=f\"The reason for the decision made on {checkpoint}. {description}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "# The parser that will look for the LLM output in my schema and return it back to me\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"\"\"Given the following checkpoints with their description from the user, \\\n",
    "                                                   assess whether they apply or not to the text you receive as input below \\\n",
    "                                                   and provide a brief explanation on the why. \\n\n",
    "                                                    {format_instructions}\\n{user_prompt}\"\"\")  \n",
    "    ],\n",
    "    input_variables=[\"user_prompt\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "key_renaming ={}\n",
    "keys_list = list(checkpoints_dict.keys())\n",
    "for i in range(len(keys_list)):\n",
    "    #print(i, keys_list[i])\n",
    "    key_renaming.update({f\"checkpoint{i+1}\": f\"checkpoint_{keys_list[i]}\"})\n",
    "    key_renaming.update({f\"reason{i+1}\": f\"reason_{keys_list[i]}\"})\n",
    "\n",
    "\n",
    "labels_from_user = \"\\n%CHECKPOINTS:\\n\\n\" + '\\n\\n'.join([f\"{key} : {value}\" for key, value in checkpoints_dict.items()])\n",
    "label_query = prompt.format_prompt(user_prompt=labels_from_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57be4ee7ce601c2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filelist = []\n",
    "for start in range(0, len(article_collection), 20):\n",
    "    end = start + 20\n",
    "    filelist.append(f\"{start}_{end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb840fd4e8ab9b3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "record2answer = {}\n",
    "missing_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd04d4dd05c13f6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chaintype = 'stuff'\n",
    "my_llm_model = ChatOpenAI(model_name='gpt-3.5-turbo-0613', temperature=0)\n",
    "selected_k = 5\n",
    "selected_fetch_k = 20\n",
    "\n",
    "for file in tqdm(filelist):    \n",
    "    db_chunk = pd.read_pickle(f\"vectorsdbs2/df_collection_{file}.pkl\")\n",
    "    rec_numbers = db_chunk['uniqueid'].to_list()\n",
    "    myindex = load_index_from_db(f\"vectorsdbs2/collection_{file}\")\n",
    "    \n",
    "    for recnumber in rec_numbers:\n",
    "        qa_chain = RetrievalQA.from_chain_type(llm=my_llm_model,\n",
    "                                           chain_type=chaintype,\n",
    "                                           retriever=myindex.as_retriever(search_type=\"mmr\",\n",
    "                                                                        search_kwargs={'fetch_k': selected_fetch_k,\n",
    "                                                                                       'k': selected_k,\n",
    "                                                                                       'filter':{'uniqueid': recnumber}}),\n",
    "                                           return_source_documents=True,\n",
    "                                           verbose=False)\n",
    "        try: \n",
    "            if recnumber in record2answer.keys():\n",
    "                pass\n",
    "            else:\n",
    "                llm_response = qa_chain({\"query\": label_query.to_string()})\n",
    "                # print(llm_response)\n",
    "                output = output_parser.parse(llm_response['result'])\n",
    "                output = restructure_dict(output, key_renaming)\n",
    "                # print(\"\\n-----------\\n\")\n",
    "                # print_bullet_points(output)\n",
    "                # print(\"\\n-----------\\n\")\n",
    "                # print(llm_response['source_documents'])\n",
    "                output['sources'] = llm_response['source_documents']\n",
    "                record2answer[recnumber] = output\n",
    "        except:\n",
    "            if recnumber in missing_records:\n",
    "                pass\n",
    "            else:\n",
    "               # print(f\"ERROR in {recnumber}:\\t{llm_response['result']}\")\n",
    "               missing_records.append(recnumber)\n",
    "                \n",
    "\n",
    "    with open(f'results/record2answer_refinedcrits.pkl', 'wb') as file:\n",
    "        pickle.dump(record2answer, file)\n",
    "\n",
    "    with open('results/missing_records_refinedcrits.pkl', 'wb') as file:\n",
    "        pickle.dump(missing_records, file)\n",
    "print(f\"CORRECTLY analyzed {len(record2answer)}\")\n",
    "print(f\"INCORRECTLY analyzed {len(missing_records)}\")\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
